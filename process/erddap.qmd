---
title: "ERDDAP Data Extraction"
date: today
date-format: iso
format:
  html:
    code-fold: true
    toc: true
    toc-depth: 3
    toc-expand: 2
    number-sections: true
editor: 
  mode: source
editor_options: 
  chunk_output_type: console
params:
  data_var: noaa_sss
  erddap_url: https://coastwatch.noaa.gov/erddap/griddap/noaacwSMOSsss3day.html
  erddap_variable: sss
  # data_var: noaa_sst
  # erddap_url: https://coastwatch.noaa.gov/erddap/griddap/noaacrwsstDaily.html
  # erddap_variable: analysed_sst
execute: 
  error: true
---

## Setup with `extractr`

```{r}
#| label: setup

# dir_extractr = "/share/github/marinebon/extractr" # dir_extractr = "~/Github/marinebon/extractr"
# devtools::load_all(dir_extractr)
# devtools::install_local(dir_extractr, force = T)
# devtools::install_github("marinebon/extractr", force = T)
librarian::shelf(
  dplyr, DT, glue, here, logger, lubridate, mapview, purrr, readr, sf, stringr,
  terra,
  marinebon/extractr)

ply_sanctuaries <- readRDS(here("../climate-dashboard/data/sanctuaries.rds")) # |> 
  # filter(nms != "HIHWNMS")  # TODO: sort dateline sanctuary later

# mapView(sanctuaries)
# sanctuaries |>
#   st_drop_geometry() |>
#   datatable()

dir_out <- here(glue("data/{params$data_var}"))
dir.create(dir_out, showWarnings = F, recursive = T)
```

## Dataset info

```{r}
#| label: ed_info

(ed <- ed_info(params$erddap_url))
times <- ed_dim(ed, "time")
(v <- params$erddap_variable)
```

## Setup iteration: sanctuary years

```{r}
#| label: d_nms_yr

d_nms_yr <- ply_sanctuaries |> 
  st_drop_geometry() |> 
  arrange(nms) |> 
  select(nms) |> 
  cross_join(
    tibble(
      year = year(min(times)):year(max(times)))) |> 
  mutate(
    all_in_csv = map2_chr(nms, year, \(nms, year) { # nms = "GRNMS"; year = 2010
      times_yr <- times[year(times) == year]
      csv <- glue("{dir_out}/{nms}/{year}.csv")
      if (!file.exists(csv))
        return(F)
      times_csv <- read_csv(csv) |> 
        pull(time)
      all(times_yr %in% times_csv) }) )

d_nms_yr_todo <- d_nms_yr |>
  filter(all_in_csv == F) |> 
  mutate(
    i = 1:n()) |> 
  relocate(i)

d_nms_yr |> 
  group_by(nms) |>
  filter(all_in_csv == F) |> 
  summarize(
    n_years   = n(),
    year_min  = min(year),
    year_max = max(year)) |>
  datatable(
    caption  = "Sanctuaries with existing CSVs missing available ERDDAP times.",
    rownames = F,
    options  = list(
      pageLength = 5,
      lengthMenu = c(5, 50, nrow(d_nms_yr))))
```

## Iterate over sanctuary years

```{r}
#| label: iterate_ed_extract

# rerddap::cache_delete_all()

fxn <- function(i, nms, year, ...){
  #  nms = "GRNMS"; year = 2010 ; i = 97    # DEBUG

 err <- tryCatch({
    
    log_info("{sprintf('%03d', i)}: {nms}, {year}")

    times_yr <- times[year(times) == year]
    
    ply <- ply_sanctuaries |>
      filter(nms == !!nms)
    # TODO: consider expanding by 10% and rounding 2 digits
    # bb <- st_bbox(ply) |> stars:::bb_shrink(-0.1) |> round(2)
    
    extractr::ed_extract(
      ed,
      var       = v,
      sf_zones  = ply,
      mask_tif  = T,
      rast_tif  = glue::glue("{dir_out}/{nms}/{year}.tif"),
      zonal_fun = "mean",
      zonal_csv = glue::glue("{dir_out}/{nms}/{year}.csv"),
      dir_nc    = glue::glue("{dir_out}/{nms}/{year}_nc"),
      keep_nc   = F,
      n_max_vals_per_req = 1e+05,
      time_min  = min(times_yr),
      time_max  = max(times_yr))
    
    return(NA)
  }, error = function(e) {
    
    log_error(conditionMessage(e))
    return(conditionMessage(e))
  })
 
 err
} 

res <- d_nms_yr_todo |> 
  # slice(1:3) |>  # DEBUG
  mutate(
    error = pmap_chr(list(i, nms, year), fxn))
```

### Successes

```{r}
#| label: success_summary

res |> 
  mutate(
    success = is.na(error)) |> 
  group_by(success) |> 
  summarize(
    n = n()) |> 
  datatable()
```

### Errors (if any)

```{r}
#| label: error_summary

res |> 
  filter(!is.na(error)) |> 
  group_by(nms) |> 
  summarize(
    n_years = n(),
    errors  = unique(error) |> paste(collapse = "\n\n----\n\n")) |> 
  datatable()
```

## TODO

`ed_extract()`:

- [x] delete *_nc dir
- [x] differentiate existing done vs todo for given year
- [ ] allow irregular datasets, like `meta/irregular/*.yaml`: `ERROR: x cell sizes are not regular`
- [ ] break up into functions, not exported

`erddap.qmd`:

- [ ] make `ed_extract()` to single MBNMS with features for main vs david; add "ALL" option to `ed_extract()`
- [ ] add buffer to all (and redo)
- [ ] wrap retry with `ed_dim()` too

```{r}
#| label: rm_empty_nc_dirs
#| eval: false
#| echo: false

# find empty directories ending in _nc and delete them
d_dirs <- tibble(
  dir = list.dirs(here("data"), full.names = T, recursive = T)) |> 
  filter(str_detect(dir, "_nc$")) |> 
  mutate(
    n_files = map_int(dir, \(x) {length(list.files(x))}))

# show non-empty directories
d_dirs |> 
  filter(n_files > 0) |> 
  datatable()

# delete empty directories
d_dirs |> 
  filter(n_files == 0) |> 
  pull(dir) |>
  walk(\(x) {
    message(glue("Deleting {x}"))
    unlink(x, recursive = T) })
```

## R package versions

```{r}
devtools::session_info()
```

